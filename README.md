# Text-Analysis-and-Entity-Resolution


Entity resolution is a common, yet difficult problem in data cleaning and integration. In this lab exercise, we will use powerful and scalable text analysis techniques to perform entity resolution across two data sets of commercial products.

Entity Resolution, or "Record linkage" is the term used by statisticians, epidemiologists, and historians, among others, to describe the process of joining records from one data source with another that describe the same entity. Our terms with the same meaning include,  "entity disambiguation/linking", "duplicate detection", "deduplication", "record matching", "(reference) reconciliation", "object identification", "data/information integration", and "conflation".

Entity Resolution (ER) refers to the task of finding records in a data set that refer to the same entity across different data sources (e.g., data files, books, websites, databases). ER is necessary when joining data sets based on entities that may or may not share a common identifier (e.g., database key, URI, National identification number), as may be the case due to differences in record shape, storage location, and/or curator style or preference. A data set that has undergone ER may be referred to as being cross-linked.


Part 1: ER as Text Similarity - Bags of Words

Part 2: ER as Text Similarity - Weighted Bag-of-Words using TF-IDF

Part 3: ER as Text Similarity - Cosine Similarity

Part 4: Scalable ER

Part 5: Analysis (this is part where you will click through and view plots of your work from part 4)
